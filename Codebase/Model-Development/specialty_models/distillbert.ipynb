{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bc9cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found, using: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU found, using: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU not found\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf19ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All outputs will be saved to: ./Saved-Models/emilyalsentzer/Bio_ClinicalBERT/training_run_2025-11-08_17-11-59\n"
     ]
    }
   ],
   "source": [
    "# MODEL_NAME = 'distilbert-base-uncased'\n",
    "MODEL_NAME = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "CSV = '../../Data/Specialty-Data/specialty_data.csv'\n",
    "MAPPINGS = '../../Data/Specialty-Data/specialty_data_label_mappings.json'\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "ROOT_OUTPUT_DIR = f\"./Saved-Models/{MODEL_NAME}/training_run_{current_time}\"\n",
    "\n",
    "TRAINING_OUTPUT_DIRECTORY = os.path.join(ROOT_OUTPUT_DIR, 'results')\n",
    "MODEL_FINAL_DIRECTORY = os.path.join(ROOT_OUTPUT_DIR, 'final_model')\n",
    "LOGGING_DIRECTORY = os.path.join(ROOT_OUTPUT_DIR, 'logs')\n",
    "\n",
    "os.makedirs(TRAINING_OUTPUT_DIRECTORY, exist_ok=True)\n",
    "os.makedirs(MODEL_FINAL_DIRECTORY, exist_ok=True)\n",
    "os.makedirs(LOGGING_DIRECTORY, exist_ok=True)\n",
    "\n",
    "print(f\"All outputs will be saved to: {ROOT_OUTPUT_DIR}\")\n",
    "\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(\n",
    "        examples['transcription'], \n",
    "        padding=\"max_length\", \n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "126ba691",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(CSV)\n",
    "    with open(MAPPINGS, 'r') as f:\n",
    "        specialty_and_id_map = json.load(f)\n",
    "except:\n",
    "    print(f\"Data not found, make sure to run the specialty_data_preprocessing.ipynb file in its entirety to retrieve the data\")\n",
    "\n",
    "label_to_id = specialty_and_id_map['label_to_id']\n",
    "id_to_label = {int(k): v for k, v in specialty_and_id_map['id_to_label'].items()}\n",
    "\n",
    "total_specialties = len(label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bdfd245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['description', 'medical_specialty', 'sample_name', 'transcription', 'keywords', 'label'],\n",
       "        num_rows: 2304\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['description', 'medical_specialty', 'sample_name', 'transcription', 'keywords', 'label'],\n",
       "        num_rows: 288\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['description', 'medical_specialty', 'sample_name', 'transcription', 'keywords', 'label'],\n",
       "        num_rows: 288\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80% Train, 10% Validation, 10% Test\n",
    "train_df, test_val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    stratify=df['label'], \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    test_val_df, \n",
    "    test_size=0.5, \n",
    "    stratify=test_val_df['label'], \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "    'validation': Dataset.from_pandas(val_df.reset_index(drop=True)),\n",
    "    'test': Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "})\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d8ab69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0aa391eafe4b048ce853b5d71297cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2304 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653a94b201bb49dab5af4b8209e61087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/288 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54231bc5fb464472bfad76e0921857d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/288 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['description', 'sample_name', 'keywords', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2304\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['description', 'sample_name', 'keywords', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 288\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['description', 'sample_name', 'keywords', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 288\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenized_ds = ds.map(lambda examples: tokenize_function(examples, tokenizer), batched=True)\n",
    "\n",
    "tokenized_ds = tokenized_ds.remove_columns(['transcription', 'medical_specialty'])\n",
    "\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7965180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\spenc\\AppData\\Local\\Temp\\ipykernel_24328\\1861476197.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Include this in the model for Bio_ClinicalBERT to force the use of safetensors vs using insecure load\n",
    "# May not be necessary on other models\n",
    "# use_safetensors=True,\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    use_safetensors=True,\n",
    "    num_labels=total_specialties,\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=TRAINING_OUTPUT_DIRECTORY,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=LOGGING_DIRECTORY,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213602c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='432' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [432/432 04:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.900200</td>\n",
       "      <td>1.596799</td>\n",
       "      <td>0.493056</td>\n",
       "      <td>0.353606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.282700</td>\n",
       "      <td>1.097798</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.458143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.037200</td>\n",
       "      <td>1.088696</td>\n",
       "      <td>0.482639</td>\n",
       "      <td>0.432584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete\n",
      "-------------------------------------\n",
      "Evaluating on validation dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results\n",
      "{'eval_loss': 1.1599992513656616, 'eval_accuracy': 0.4791666666666667, 'eval_f1': 0.4499210145571289, 'eval_runtime': 3.7312, 'eval_samples_per_second': 77.187, 'eval_steps_per_second': 4.824, 'epoch': 3.0}\n",
      "Saving final model to ./Saved-Models/emilyalsentzer/Bio_ClinicalBERT/training_run_2025-11-08_17-11-59\\final_model\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Model\")\n",
    "trainer.train()\n",
    "print(f\"Training Complete\")\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "print(f\"Evaluating on validation dataset\")\n",
    "test_results = trainer.evaluate(tokenized_ds[\"test\"])\n",
    "\n",
    "print(f\"Validation results\")\n",
    "print(test_results)\n",
    "\n",
    "with open(f\"{TRAINING_OUTPUT_DIRECTORY}/test_results.json\", 'w') as f:\n",
    "    json.dump(test_results, f, indent=4)\n",
    "\n",
    "print(f\"Saving final model to {MODEL_FINAL_DIRECTORY}\")\n",
    "trainer.save_model(MODEL_FINAL_DIRECTORY)\n",
    "print(f\"Model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
